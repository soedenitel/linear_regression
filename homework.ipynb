{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b987e9ea",
   "metadata": {},
   "source": [
    "# Описание задания\n",
    "Загрузите данные и посчитайте модели линейной регрессии для 50 зданий по ансамблю регрессионных моделей:\n",
    "* в первой модели весь оптимальный набор метеорологических данных,\n",
    "* во второй - дни недели и праздники,\n",
    "* в третьей - недели года,\n",
    "* в четвертой - месяцы.\n",
    "\n",
    "Финальное значение показателя рассчитайте как взвешенное арифметическое среднее показателей всех моделей, взяв веса для первой и второй модели как 3/8, а для третьей и четвертой - как 1/8.\n",
    "\n",
    "Загрузите данные решения, посчитайте значение энергопотребления для требуемых дат для тех зданий, которые посчитаны в модели, и выгрузите результат в виде CSV-файла (submission.csv).\n",
    "\n",
    "Данные:\n",
    "* http://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz\n",
    "* http://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz\n",
    "* http://video.ittensive.com/machine-learning/ashrae/train.0.csv.gz\n",
    "* http://video.ittensive.com/machine-learning/ashrae/test.csv.gz\n",
    "* http://video.ittensive.com/machine-learning/ashrae/weather_test.csv.gz\n",
    "\n",
    "Итоговый файл с кодом (.py или .ipynb) выложите в github с портфолио.\n",
    "<a id='task_definition'></a>\n",
    "## 1. Определение задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92a6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_BUILDINGS_FOR_MODELLING = 50\n",
    "\n",
    "WEEKDAY_FEATURES = ['is_wd' + str(i) for i in range(0, 7)]\n",
    "WEEK_FEATURES = ['is_week' + str(i) for i in range(1, 54)]\n",
    "MONTH_FEATURES = ['is_month' + str(i) for i in range(1, 13)]\n",
    "\n",
    "FEATURE_TYPES = {\n",
    "    1: #в первой модели весь оптимальный набор метеорологических данных\n",
    "    [\n",
    "        'air_temperature', 'dew_temperature', 'sea_level_pressure', 'wind_speed', 'cloud_coverage',\n",
    "        'air_temperature_diff1', 'air_temperature_diff2'\n",
    "    ],\n",
    "    \n",
    "    2: #во второй - дни недели и праздники\n",
    "    WEEKDAY_FEATURES + ['is_holiday'],\n",
    "    \n",
    "    3: #в третьей - недели года\n",
    "    WEEK_FEATURES,\n",
    "    \n",
    "    4: #в четвертой - месяцы\n",
    "    MONTH_FEATURES\n",
    "}\n",
    "\n",
    "TARGET_FEATURE = 'meter_reading'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d886b23",
   "metadata": {},
   "source": [
    "<a id='etl'></a>\n",
    "## 2. ETL\n",
    "[Вспомогательные функции для очистки и преобразования исходных данных](etl_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13a6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "pd.set_option('display.max_columns', 200)\n",
    "from etl_utils import reduce_mem_usage, show_inf_and_na, inf_and_na_columns\n",
    "\n",
    "\n",
    "def assemble_the_data(energy_df, weather_df, buildings_df, max_building_number=NUMBER_OF_BUILDINGS_FOR_MODELLING):\n",
    "    assembeled_df = energy_df[energy_df['building_id'] < max_building_number]\n",
    "    assembeled_df = pd.merge(left=assembeled_df, right=buildings_df, how='left', left_on='building_id', right_on='building_id')\n",
    "    assembeled_df = pd.merge(\n",
    "        left=assembeled_df.set_index(['timestamp', 'site_id']), \n",
    "        right=weather_df.set_index(['timestamp', 'site_id']),\n",
    "        how='left', left_index=True, right_index=True\n",
    "    )\n",
    "    assembeled_df.reset_index(inplace=True)\n",
    "    assembeled_df[\"precip_depth_1_hr\"] = assembeled_df[\"precip_depth_1_hr\"].map(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    for column in inf_and_na_columns(assembeled_df):\n",
    "        assembeled_df[column] = assembeled_df[column].interpolate(limit_direction='both', kind='cubic')\n",
    "    assembeled_df = assembeled_df.drop(inf_and_na_columns(assembeled_df), axis='columns')\n",
    "    return reduce_mem_usage(assembeled_df)\n",
    "\n",
    "\n",
    "def enrich_weather_data(df: pd.DataFrame):\n",
    "    df['air_temperature_diff1'] = df['air_temperature'].diff()\n",
    "    df.at[0, 'air_temperature_diff1'] = df.at[1, 'air_temperature_diff1']\n",
    "    df['air_temperature_diff2'] = df['air_temperature_diff1'].diff()\n",
    "    df.at[0, 'air_temperature_diff2'] = df.at[1, 'air_temperature_diff2']\n",
    "    return  df\n",
    "\n",
    "\n",
    "def generate_one_hot_column_df(feature_values: pd.Series, columns: list):\n",
    "    df = pd.get_dummies(feature_values)\n",
    "    for i in range(df.shape[1], len(columns)): # если one_hot_vector получился короче, чем columns\n",
    "        df[columns[i]] = 0\n",
    "    return df.set_axis(columns, axis='columns')\n",
    "\n",
    "\n",
    "def enrich_date_data(df: pd.DataFrame):\n",
    "    us_holidays = calendar().holidays(start=df['timestamp'].dt.date.min(), end=df['timestamp'].dt.date.max())\n",
    "    df['is_holiday'] = df['timestamp'].isin(us_holidays).astype('int8')\n",
    "    \n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=generate_one_hot_column_df(df['timestamp'].dt.weekday.astype('int8'), WEEKDAY_FEATURES),\n",
    "        left_index=True, right_index=True\n",
    "    )\n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=generate_one_hot_column_df(df['timestamp'].dt.isocalendar().week.astype('int8'), WEEK_FEATURES),\n",
    "        left_index=True, right_index=True\n",
    "    )    \n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=generate_one_hot_column_df(df['timestamp'].dt.month.astype('int8'), MONTH_FEATURES),\n",
    "        left_index=True, right_index=True\n",
    "    )\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad25b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 35.47 Мб (-71.7%)\n",
      "Потребление памяти меньше на 84.21 Мб (-70.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((269067, 90), (1051200, 90))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings_df = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/building_metadata.csv.gz')\n",
    "\n",
    "weather_train_df = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/weather_train.csv.gz')\n",
    "energy_train_df = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/train.0.csv.gz')\n",
    "\n",
    "weather_test_df = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/weather_test.csv.gz')\n",
    "energy_test_df = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/test.csv.gz')\n",
    "\n",
    "train_df = enrich_date_data(enrich_weather_data(assemble_the_data(energy_train_df, weather_train_df, buildings_df)))\n",
    "train_df = train_df[train_df[TARGET_FEATURE] > 0]\n",
    "del energy_train_df\n",
    "del weather_train_df\n",
    "\n",
    "test_df = enrich_date_data(enrich_weather_data(assemble_the_data(energy_test_df, weather_test_df, buildings_df)))\n",
    "del energy_test_df\n",
    "del weather_test_df\n",
    "del buildings_df\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f56186f",
   "metadata": {},
   "source": [
    "<a id='modelling'></a>\n",
    "## 3. Построение для каждого типа (набора признаков) моделей линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc76571e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип 1 - всего моделей: 1200\n",
      "Тип 2 - всего моделей: 1200\n",
      "Тип 3 - всего моделей: 1200\n",
      "Тип 4 - всего моделей: 1200\n"
     ]
    }
   ],
   "source": [
    "def models_amount(models):\n",
    "    amount = 0\n",
    "    for i in range(len(models)):\n",
    "        amount += len(models[i])\n",
    "    return amount\n",
    "\n",
    "\n",
    "def generate_hourly_models(df: pd.DataFrame, x_columns: list, y_column: str) -> dict:\n",
    "    '''\n",
    "    Генерирует набор моделей линейной регрессии.\n",
    "    Количество моделей соответствует колчеству часов представленных в df['timestamp']\n",
    "    df['timestamp'] - ОБЯЗАТЕЛЬНЫЙ столбец во фрейме данных\n",
    "    x_columns - список столбцов, которые используются в качестве входных данных (факторных переменных) при обучении моделей\n",
    "    y_column - столбец целевой переменной при обучении моделей\n",
    "    \n",
    "    Возвращает словарь в котором ключ - это час, а значение - модель для этого часа\n",
    "    '''\n",
    "    hourly_models = dict()\n",
    "    for hour in range(0, df['timestamp'].dt.hour.max() + 1):\n",
    "        hour_data = df[df['timestamp'].dt.hour == hour]\n",
    "        if len(hour_data) > 0:\n",
    "            hourly_models[hour] = LinearRegression().fit(hour_data[x_columns].values, hour_data[y_column].values)\n",
    "    return hourly_models\n",
    "\n",
    "\n",
    "ensemble = dict()\n",
    "for model_type in FEATURE_TYPES:\n",
    "    ensemble[model_type] = dict()\n",
    "    for building_id in range(0, train_df['building_id'].max() + 1):\n",
    "        ensemble[model_type][building_id] = generate_hourly_models(\n",
    "            df=train_df[train_df['building_id'] == building_id],\n",
    "            x_columns=FEATURE_TYPES[model_type],\n",
    "            y_column=TARGET_FEATURE\n",
    "        )\n",
    "    print('Тип', model_type, '- всего моделей:', models_amount(ensemble[model_type]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2930cb",
   "metadata": {},
   "source": [
    "<a id='prediction'></a>\n",
    "## 4. Построение прогнозов для каждого типа моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61cda0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(row, x_columns, models):\n",
    "    '''\n",
    "    Строит прогнозное значение\n",
    "    row - кортеж входных данных    \n",
    "    row['building_id'] - ОБЯЗАТЕЛЬНЫЙ атрибут во входном кортеже данных\n",
    "    row['timestamp'] - ОБЯЗАТЕЛЬНЫЙ атрибут во входном кортеже данных\n",
    "    \n",
    "    x_columns - список названий атрибутов из row, по которым нужно построить прогноз\n",
    "    models - словарь, в котором располагаются модели по последовательности ключей: [идентификатор здания][час] \n",
    "    Возвращает число float\n",
    "    '''\n",
    "    result = 0\n",
    "    building_id = row['building_id']\n",
    "    if building_id in models.keys():\n",
    "        hour = row['timestamp'].hour\n",
    "        if hour in models[building_id].keys():\n",
    "            result = models[building_id][hour].predict(row[x_columns].values.reshape(1, -1))[0]\n",
    "    \n",
    "    if result < 0:\n",
    "        result = 0\n",
    "    return np.float16(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91a9e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип 1 - прогнозы построены.\n",
      "Тип 2 - прогнозы построены.\n",
      "Тип 3 - прогнозы построены.\n",
      "Тип 4 - прогнозы построены.\n",
      "CPU times: total: 26min 24s\n",
      "Wall time: 26min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = dict()\n",
    "for model_type in FEATURE_TYPES:\n",
    "    predictions[model_type] = test_df.apply(\n",
    "        make_prediction,\n",
    "        axis='columns',\n",
    "        x_columns=FEATURE_TYPES[model_type],\n",
    "        models=ensemble[model_type]\n",
    "    )\n",
    "    print('Тип', model_type, '- прогнозы построены.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be33d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_type in FEATURE_TYPES:\n",
    "    predictions[model_type].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30183401",
   "metadata": {},
   "source": [
    "<a id='result'></a>\n",
    "## 5. Вычисление финального значения как взвешенного арифметического среднего:\n",
    "* веса для первой и второй модели как 3/8\n",
    "* третьей и четвертой - как 1/8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f10ae456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>283.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1245.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  meter_reading\n",
       "0       0     186.000000\n",
       "1       1      82.000000\n",
       "2       2       7.945312\n",
       "3       3     283.000000\n",
       "4       4    1245.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[TARGET_FEATURE] = ((3/8) * predictions[1] + (3/8) * predictions[2] + (1/8) * predictions[3] + (1/8) * predictions[4])\n",
    "results_df = test_df[['row_id', TARGET_FEATURE]]\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac02c3",
   "metadata": {},
   "source": [
    "<a id='create_submision'></a>\n",
    "## 6. Формирование выгрузки данных для тех зданий, которые посчитаны в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e64201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 159.06 Мб (-22.2%)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41697600 entries, 0 to 41697599\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   row_id         int32  \n",
      " 1   meter_reading  float16\n",
      "dtypes: float16(1), int32(1)\n",
      "memory usage: 556.7 MB\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.read_csv('http://video.ittensive.com/machine-learning/ashrae/test.csv.gz', usecols=['row_id'])\n",
    "submission_df = pd.merge(left=submission_df, right=results_df, how='left', left_on='row_id', right_on='row_id')\n",
    "submission_df = reduce_mem_usage(submission_df.fillna(0))\n",
    "submission_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763c80b",
   "metadata": {},
   "source": [
    "<a id='save_submision'></a>\n",
    "## 7. Выгрузка результат в виде CSV-файла (submission.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661b7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296dae9",
   "metadata": {},
   "source": [
    "### Освобождение памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83c52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df\n",
    "del test_df\n",
    "del results_df\n",
    "del submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
